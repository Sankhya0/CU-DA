{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Diffusion Replay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:30:34.805079Z",
     "iopub.status.busy": "2025-05-06T19:30:34.804787Z",
     "iopub.status.idle": "2025-05-06T19:30:58.896827Z",
     "shell.execute_reply": "2025-05-06T19:30:58.895861Z",
     "shell.execute_reply.started": "2025-05-06T19:30:34.80506Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from diffusers import UNet1DModel, DDPMScheduler\n",
    "from copy import deepcopy\n",
    "from models.unet.unet_1d_condition import UNet1DConditionModel\n",
    "from diffusers import DPMSolverMultistepScheduler\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:30:33.435177Z",
     "iopub.status.busy": "2025-05-06T19:30:33.434865Z",
     "iopub.status.idle": "2025-05-06T19:30:33.439135Z",
     "shell.execute_reply": "2025-05-06T19:30:33.438229Z",
     "shell.execute_reply.started": "2025-05-06T19:30:33.435155Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/kaggle/working/diffusers-unet-1d-condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:01.452972Z",
     "iopub.status.busy": "2025-05-06T19:31:01.451854Z",
     "iopub.status.idle": "2025-05-06T19:31:07.521952Z",
     "shell.execute_reply": "2025-05-06T19:31:07.521196Z",
     "shell.execute_reply.started": "2025-05-06T19:31:01.452945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.login(key=\"1e41cd1b20b6ece9ffa899875a14d6311963debe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:07.523836Z",
     "iopub.status.busy": "2025-05-06T19:31:07.52324Z",
     "iopub.status.idle": "2025-05-06T19:31:07.529481Z",
     "shell.execute_reply": "2025-05-06T19:31:07.52863Z",
     "shell.execute_reply.started": "2025-05-06T19:31:07.523814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_ROOT    = \"/kaggle/input/officehome/OfficeHome\"\n",
    "DOMAINS      = [\"Product\", \"Art\", \"Clipart\", \"RealWorld\"]\n",
    "IMG_SIZE     = 224\n",
    "BATCH_SIZE   = 64\n",
    "LR           = 1e-4\n",
    "NUM_EPOCHS   = {\n",
    "    \"BASE_SOURCE_TRAIN\": 50,\n",
    "}\n",
    "PATIENCE     = 5\n",
    "\n",
    "\n",
    "TH_START = 0.6\n",
    "TH_END = 0.9\n",
    "ENT_WEIGHT = 0.1\n",
    "EMA_DECAY = 0.995\n",
    "\n",
    "FEATURE_DIM      = 512     \n",
    "DIFFUSION_STEPS  = 1000\n",
    "DIFFUSION_EPOCHS = 5\n",
    "\n",
    "SOURCE_DOM = \"RealWorld\"\n",
    "DOWN_DOM = [\"Product\", \"Clipart\", \"Art\"]\n",
    "DOMAINS = [\"RealWorld\", \"Product\", \"Clipart\", \"Art\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:11.476488Z",
     "iopub.status.busy": "2025-05-06T19:31:11.476148Z",
     "iopub.status.idle": "2025-05-06T19:31:11.484466Z",
     "shell.execute_reply": "2025-05-06T19:31:11.483598Z",
     "shell.execute_reply.started": "2025-05-06T19:31:11.476466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Defining the loaders and transforms\n",
    "\n",
    "def get_transforms(img_size=IMG_SIZE):\n",
    "    train_t = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std =[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    test_t = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                             std =[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    return train_t, test_t\n",
    "\n",
    "def load_domain(domain, val_split=0.1, test_split=0.1):\n",
    "    train_t, test_t = get_transforms()\n",
    "    path = os.path.join(DATA_ROOT, domain)\n",
    "    ds = datasets.ImageFolder(path, transform=train_t)\n",
    "    n = len(ds)\n",
    "    v = int(val_split * n)\n",
    "    t = int(test_split * n)\n",
    "    train_ds, val_ds, test_ds = random_split(\n",
    "        ds,\n",
    "        [n - v - t, v, t],\n",
    "        generator=torch.Generator().manual_seed(SEED)\n",
    "    )\n",
    "    val_ds.dataset.transform  = test_t\n",
    "    test_ds.dataset.transform = test_t\n",
    "    return {\n",
    "        \"train\": DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True),\n",
    "        \"val\":   DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False),\n",
    "        \"test\":  DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False),\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:13.878119Z",
     "iopub.status.busy": "2025-05-06T19:31:13.877794Z",
     "iopub.status.idle": "2025-05-06T19:31:19.468572Z",
     "shell.execute_reply": "2025-05-06T19:31:19.467412Z",
     "shell.execute_reply.started": "2025-05-06T19:31:13.878096Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Checking loaders\n",
    "\n",
    "rw_loaders = load_domain(\"RealWorld\")\n",
    "print(\"Found classes:\", rw_loaders[\"train\"].dataset.dataset.classes)\n",
    "imgs, labels = next(iter(rw_loaders[\"train\"]))\n",
    "print(\"Batch shape:\", imgs.shape, \"— labels example:\", labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T08:49:53.977353Z",
     "iopub.status.busy": "2025-05-04T08:49:53.976966Z",
     "iopub.status.idle": "2025-05-04T08:49:56.841049Z",
     "shell.execute_reply": "2025-05-04T08:49:56.840287Z",
     "shell.execute_reply.started": "2025-05-04T08:49:53.977334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Build a table of (domain, class, num_images)\n",
    "records = []\n",
    "for domain in DOMAINS:\n",
    "    domain_path = os.path.join(DATA_ROOT, domain)\n",
    "    for cls in sorted(os.listdir(domain_path)):\n",
    "        cls_path = os.path.join(domain_path, cls)\n",
    "        if not os.path.isdir(cls_path):\n",
    "            continue\n",
    "        num_imgs = sum(\n",
    "            1 for fname in os.listdir(cls_path)\n",
    "            if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))\n",
    "        )\n",
    "        records.append({\"domain\": domain, \"class\": cls, \"num_images\": num_imgs})\n",
    "\n",
    "eda_df = pd.DataFrame(records)\n",
    "\n",
    "# 1. Check class name consistency\n",
    "class_sets = {d: set(eda_df[eda_df['domain']==d]['class']) for d in DOMAINS}\n",
    "common_classes = set.intersection(*class_sets.values())\n",
    "extra = {d: class_sets[d] - common_classes for d in DOMAINS}\n",
    "missing = {d: common_classes - class_sets[d] for d in DOMAINS}\n",
    "\n",
    "print(f\"Number of common classes across all domains: {len(common_classes)}\")\n",
    "for d in DOMAINS:\n",
    "    print(f\"- {d}: {len(class_sets[d])} classes, {len(extra[d])} extra, {len(missing[d])} missing\")\n",
    "\n",
    "print(\"\\nExtra classes by domain:\")\n",
    "for d, ex in extra.items():\n",
    "    print(f\"  {d}: {sorted(ex)}\")\n",
    "print(\"\\nMissing classes by domain:\")\n",
    "for d, ms in missing.items():\n",
    "    print(f\"  {d}: {sorted(ms)}\")\n",
    "\n",
    "# 2. Check per-class image count consistency\n",
    "pivot = eda_df.pivot(index='class', columns='domain', values='num_images').fillna(0).astype(int)\n",
    "display(pivot.head())\n",
    "\n",
    "# Identify classes with differing counts\n",
    "inconsistent = pivot[pivot.nunique(axis=1) > 1]\n",
    "print(f\"\\nClasses with differing image counts across domains ({len(inconsistent)}):\")\n",
    "print(inconsistent.index.tolist())\n",
    "\n",
    "# 3. (Optional) Visualize count distribution for inconsistent classes\n",
    "if not inconsistent.empty:\n",
    "    inconsistent.plot.bar(figsize=(10,4))\n",
    "    plt.title(\"Image Count per Class for Inconsistent Classes\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:19.470308Z",
     "iopub.status.busy": "2025-05-06T19:31:19.469976Z",
     "iopub.status.idle": "2025-05-06T19:31:19.476758Z",
     "shell.execute_reply": "2025-05-06T19:31:19.476039Z",
     "shell.execute_reply.started": "2025-05-06T19:31:19.47026Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Model Definitions\n",
    "\n",
    "def build_resnet(num_classes):\n",
    "    m = models.resnet50(pretrained=True)\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m.to(device)\n",
    "\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            pred = model(x).argmax(1)\n",
    "            correct += (pred==y).sum().item(); total += y.size(0)\n",
    "    return 100*correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T18:25:13.60954Z",
     "iopub.status.busy": "2025-05-06T18:25:13.609298Z",
     "iopub.status.idle": "2025-05-06T18:25:21.12846Z",
     "shell.execute_reply": "2025-05-06T18:25:21.127788Z",
     "shell.execute_reply.started": "2025-05-06T18:25:13.609524Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"FDR_UCDA\",\n",
    "    name=\"base_classifier_real_world\",\n",
    "    config={\n",
    "        \"domain\": \"Real_World\",\n",
    "        \"model\": \"resnet50\",\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"lr\": LR,\n",
    "        \"epochs\": NUM_EPOCHS[\"BASE_SOURCE_TRAIN\"],\n",
    "        \"patience\": PATIENCE\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T09:27:34.187868Z",
     "iopub.status.busy": "2025-05-04T09:27:34.187114Z",
     "iopub.status.idle": "2025-05-04T09:27:34.198561Z",
     "shell.execute_reply": "2025-05-04T09:27:34.197773Z",
     "shell.execute_reply.started": "2025-05-04T09:27:34.187841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_base(model, loaders, epochs, patience, device):\n",
    "    # Logging\n",
    "    config = wandb.config\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=50)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        running_total = 0\n",
    "\n",
    "        for imgs, labels in tqdm(loaders[\"train\"], desc=f\"Train Epoch {epoch}/{epochs}\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            running_correct += (preds == labels).sum().item()\n",
    "            running_total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / running_total\n",
    "        train_acc = 100 * running_correct / running_total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct, val_total = 0, 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loaders[\"val\"]:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        val_loss /= val_total\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "\n",
    "        # Log to W&B\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc\n",
    "        })\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train loss={train_loss:.4f}, acc={train_acc:.2f}% | \"\n",
    "              f\"Val loss={val_loss:.4f}, acc={val_acc:.2f}%\")\n",
    "\n",
    "        # Early stopping & checkpoint\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"best_base_model.pth\")\n",
    "            print(f\"New best model saved (val_acc={val_acc:.2f}%)\")\n",
    "            wandb.save(\"best_base_model.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Stopping early at epoch {epoch} (no improvement in {patience} epochs)\")\n",
    "                break\n",
    "\n",
    "    # Load best weights\n",
    "    model.load_state_dict(torch.load(\"best_base_model.pth\"))\n",
    "    final_test_acc = validate(model, loaders[\"test\"])\n",
    "    print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n",
    "    wandb.log({\"test_acc\": final_test_acc})\n",
    "    wandb.finish()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T09:27:37.25248Z",
     "iopub.status.busy": "2025-05-04T09:27:37.251923Z",
     "iopub.status.idle": "2025-05-04T09:47:38.452874Z",
     "shell.execute_reply": "2025-05-04T09:47:38.452355Z",
     "shell.execute_reply.started": "2025-05-04T09:27:37.252454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Usage:\n",
    "rw_loaders = load_domain(SOURCE_DOM)\n",
    "model = build_resnet(len(rw_loaders[\"train\"].dataset.dataset.classes))\n",
    "model = train_base(model, rw_loaders, NUM_EPOCHS[\"BASE_SOURCE_TRAIN\"], patience=3, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Shot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:34:23.613247Z",
     "iopub.status.busy": "2025-05-06T19:34:23.612967Z",
     "iopub.status.idle": "2025-05-06T19:34:27.923854Z",
     "shell.execute_reply": "2025-05-06T19:34:27.92312Z",
     "shell.execute_reply.started": "2025-05-06T19:34:23.613229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pr_loader   = load_domain(\"Product\")\n",
    "art_loader  = load_domain(\"Art\")\n",
    "cart_loader = load_domain(\"Clipart\")\n",
    "\n",
    "base_model = build_resnet(len(rw_loaders[\"train\"].dataset.dataset.classes))\n",
    "base_model.load_state_dict(torch.load('best_base_model.pth', weights_only=True))\n",
    "\n",
    "# for loader in [rw_loaders, pr_loader, art_loader, cart_loader]:\n",
    "#     base_model.eval()\n",
    "#     correct = total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for x,y in loader['val']:\n",
    "#             x,y = x.to(device), y.to(device)\n",
    "#             pred = base_model(x).argmax(1)\n",
    "#             correct += (pred==y).sum().item(); total += y.size(0)\n",
    "#     print(100*correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "|Domain | Accuracy (%) |\n",
    "|----------------|--------------|\n",
    "| Real World        | **84.60**    |\n",
    "| Product            | **72.46**    |\n",
    "| Art       | **58.68**    |\n",
    "| Clip Art         | **52.98**    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T05:13:29.679551Z",
     "iopub.status.busy": "2025-05-05T05:13:29.679273Z",
     "iopub.status.idle": "2025-05-05T05:13:29.685237Z",
     "shell.execute_reply": "2025-05-05T05:13:29.684689Z",
     "shell.execute_reply.started": "2025-05-05T05:13:29.679532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downstream Training without Handling Catastrophic Forgetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T13:59:35.840215Z",
     "iopub.status.busy": "2025-05-04T13:59:35.839696Z",
     "iopub.status.idle": "2025-05-04T13:59:42.863514Z",
     "shell.execute_reply": "2025-05-04T13:59:42.862959Z",
     "shell.execute_reply.started": "2025-05-04T13:59:35.840194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"FDR_UCDA\",\n",
    "    name=\"pseudo_only_adapt\",\n",
    "    config={\n",
    "        \"domains\": DOMAINS,\n",
    "        \"lr\": 1e-4,\n",
    "        \"epochs_per_domain\": 20,\n",
    "        \"patience\": 3,\n",
    "        \"pseudo_thresh\": 0.9\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:33.493812Z",
     "iopub.status.busy": "2025-05-06T19:31:33.49347Z",
     "iopub.status.idle": "2025-05-06T19:31:37.894451Z",
     "shell.execute_reply": "2025-05-06T19:31:37.893789Z",
     "shell.execute_reply.started": "2025-05-06T19:31:33.493784Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loaders = {i: load_domain(i) for i in DOMAINS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:37.895879Z",
     "iopub.status.busy": "2025-05-06T19:31:37.895563Z",
     "iopub.status.idle": "2025-05-06T19:31:37.907284Z",
     "shell.execute_reply": "2025-05-06T19:31:37.906456Z",
     "shell.execute_reply.started": "2025-05-06T19:31:37.895851Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_highconf_pseudolabels(model, imgs, threshold=0.8):\n",
    "    with torch.no_grad():\n",
    "        logits = model(imgs)\n",
    "        probs = nn.Softmax(dim=1)(logits)\n",
    "    conf, y_hat = probs.max(dim=1)\n",
    "    mask = conf > threshold\n",
    "    return mask, y_hat\n",
    "\n",
    "def adapt_wo_replay(model, loaders, epochs, threshold_start, threshold_end,\n",
    "    lr=1e-5, weight_decay=1e-4, alpha=0.5, ema_decay=0.999, device='cuda', patience = 3):\n",
    "    # Logging\n",
    "    teacher = deepcopy(model)\n",
    "    for p in teacher.parameters(): p.requires_grad = False\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr=lr, weight_decay=weight_decay\n",
    "    )\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")  # for soft labels\n",
    "\n",
    "    total_steps = epochs * len(loaders[\"train\"])\n",
    "    step = 0\n",
    "\n",
    "    counter = 0\n",
    "    max_val_acc = 0\n",
    "    best_model_name = \"\"\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        teacher.train()  # teacher stays in train mode for batchnorm stats\n",
    "        for imgs, _ in loaders[\"train\"]:\n",
    "            imgs = imgs.to(device)\n",
    "            step += 1\n",
    "\n",
    "            # 1) Teacher predictions → soft pseudo-labels\n",
    "            with torch.no_grad():\n",
    "                t_logits = teacher(imgs)\n",
    "                t_probs  = F.softmax(t_logits, dim=1).float()\n",
    "\n",
    "            # 2) Student predictions\n",
    "            s_logits = model(imgs)\n",
    "            s_logprobs = F.log_softmax(s_logits, dim=1).float()\n",
    "\n",
    "            # 3) Compute dynamic threshold\n",
    "            thresh = threshold_start + (threshold_end - threshold_start) * (step / total_steps)\n",
    "\n",
    "            # 4) Mask & pseudo-label loss on high‑conf samples\n",
    "            conf, _ = t_probs.max(dim=1)\n",
    "            mask = conf > thresh\n",
    "            if mask.any():\n",
    "                loss_pseudo = criterion(\n",
    "                    s_logprobs[mask], t_probs[mask]\n",
    "                )\n",
    "            else:\n",
    "                loss_pseudo = torch.tensor(0.0, device=device)\n",
    "\n",
    "            # 5) Entropy minimization on all samples\n",
    "            loss_ent = -(F.softmax(s_logits, dim=1) * s_logprobs).sum(dim=1).mean()\n",
    "\n",
    "            loss = alpha * loss_pseudo + (1-alpha) * loss_ent\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 6) EMA update of teacher\n",
    "            with torch.no_grad():\n",
    "                for tp, sp in zip(teacher.parameters(), model.parameters()):\n",
    "                    tp.data.mul_(ema_decay).add_(sp.data, alpha=1-ema_decay)\n",
    "\n",
    "        # Validation\n",
    "        val_acc = validate(model, loaders[\"val\"])\n",
    "        val_loss = 0.0  # compute on val set as usual\n",
    "        print(f\"Epoch {epoch}: Val Acc={val_acc:.2f}%\")\n",
    "\n",
    "        if (val_acc > max_val_acc):\n",
    "            torch.save(model.state_dict(), f\"best_model_{epoch}.pth\")\n",
    "            best_model_name = f\"best_model_{epoch}.pth\"\n",
    "            counter = 0\n",
    "            max_val_acc = val_acc\n",
    "        else:\n",
    "            counter+=1\n",
    "\n",
    "        if (counter > patience):\n",
    "            model.load_state_dict(torch.load(best_model_name, weights_only=True))\n",
    "            return model\n",
    "            \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:24:35.851302Z",
     "iopub.status.busy": "2025-05-04T14:24:35.850819Z",
     "iopub.status.idle": "2025-05-04T14:27:08.982429Z",
     "shell.execute_reply": "2025-05-04T14:27:08.981653Z",
     "shell.execute_reply.started": "2025-05-04T14:24:35.851279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run adaptation to Product\n",
    "base_model = adapt_wo_replay(\n",
    "    base_model, \n",
    "    loaders[\"Product\"], \n",
    "    epochs=5,\n",
    "    threshold_start=0.7,\n",
    "    threshold_end=0.9,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:31:58.484775Z",
     "iopub.status.busy": "2025-05-04T14:31:58.484428Z",
     "iopub.status.idle": "2025-05-04T14:32:17.036866Z",
     "shell.execute_reply": "2025-05-04T14:32:17.036198Z",
     "shell.execute_reply.started": "2025-05-04T14:31:58.484752Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for loader in [rw_loaders, pr_loader, art_loader, cart_loader]:\n",
    "    base_model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader['test']:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            pred = base_model(x).argmax(1)\n",
    "            correct += (pred==y).sum().item(); total += y.size(0)\n",
    "    print(100*correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear increase in acc here but decrease due to catastrophic forgetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:50:37.623657Z",
     "iopub.status.busy": "2025-05-04T14:50:37.623073Z",
     "iopub.status.idle": "2025-05-04T14:52:37.689504Z",
     "shell.execute_reply": "2025-05-04T14:52:37.688756Z",
     "shell.execute_reply.started": "2025-05-04T14:50:37.623635Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run adaptation to Product\n",
    "base_model = adapt_wo_replay(\n",
    "    base_model, \n",
    "    loaders[\"Art\"], \n",
    "    epochs=5,\n",
    "    threshold_start=0.7,\n",
    "    threshold_end=0.9,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T14:52:41.819275Z",
     "iopub.status.busy": "2025-05-04T14:52:41.818403Z",
     "iopub.status.idle": "2025-05-04T14:52:58.644813Z",
     "shell.execute_reply": "2025-05-04T14:52:58.64414Z",
     "shell.execute_reply.started": "2025-05-04T14:52:41.819243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for loader in [rw_loaders, pr_loader, art_loader, cart_loader]:\n",
    "    base_model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader['test']:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            pred = base_model(x).argmax(1)\n",
    "            correct += (pred==y).sum().item(); total += y.size(0)\n",
    "    print(100*correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-space Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ConditionalFeatureDDPM(nn.Module):\n",
    "    def __init__(self, feat_dim, num_classes, num_domains):\n",
    "        super().__init__()\n",
    "        self.class_embed  = nn.Embedding(num_classes, feat_dim)\n",
    "        self.domain_embed = nn.Embedding(num_domains, feat_dim)\n",
    "        self.unet = UNet1DModel(\n",
    "            sample_size=feat_dim, in_channels=1, out_channels=1,\n",
    "            block_out_channels=(64,128,128,64), layers_per_block=2,\n",
    "            down_block_types=(\"DownBlock1D\",\"DownBlock1D\",\"AttnDownBlock1D\",\"DownBlock1D\"),\n",
    "            up_block_types  =(\"UpBlock1D\",\"AttnUpBlock1D\",\"UpBlock1D\",\"UpBlock1D\")\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t, class_ids, domain_ids):\n",
    "        # x: [B,1,feat], t:[B], class_ids/domain_ids:[B]\n",
    "        c = self.class_embed(class_ids).unsqueeze(1)   # [B,1,feat]\n",
    "        d = self.domain_embed(domain_ids).unsqueeze(1) # [B,1,feat]\n",
    "        return self.unet(x + c + d, t).sample         # predicted noise\n",
    "\n",
    "def sample_replay_feats(ddpm, scheduler, class_ids, domain_ids, device):\n",
    "    B = len(class_ids)\n",
    "    x = torch.randn(B,1,ddpm.unet.config.sample_size, device=device)\n",
    "    scheduler.set_timesteps(scheduler.num_train_timesteps)\n",
    "    for t in scheduler.timesteps:\n",
    "        eps = ddpm(x, t.expand(B), class_ids, domain_ids)\n",
    "        x   = scheduler.step(eps, t, x).prev_sample\n",
    "    return x.squeeze(1)  # [B, feat_dim]\n",
    "\n",
    "\n",
    "class MeanTeacher:\n",
    "    def __init__(self, student, ema_decay=0.99):\n",
    "        self.student = student\n",
    "        self.teacher = deepcopy(student).eval()\n",
    "        for p in self.teacher.parameters(): p.requires_grad = False\n",
    "        self.ema_decay = ema_decay\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_teacher(self):\n",
    "        for t_p, s_p in zip(self.teacher.parameters(), self.student.parameters()):\n",
    "            t_p.data.mul_(self.ema_decay).add_(s_p.data, alpha=1-self.ema_decay)\n",
    "\n",
    "# ---------------------\n",
    "# 3) BASE CLASSIFIER\n",
    "# ---------------------\n",
    "def build_classifier(num_classes):\n",
    "    m = models.resnet18(pretrained=True)\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "# ---------------------\n",
    "# 4) TRAINING LOOP\n",
    "# ---------------------\n",
    "def train_with_diffusion_replay(\n",
    "    student, ddpm, scheduler,\n",
    "    source_feats, source_labels,    # tensors on CPU\n",
    "    domain_order,                   # e.g. [\"Real_World\",\"Art\",\"Clipart\",\"Product\"]\n",
    "    data_loaders,                   # dict domain->{\"train\",\"val\",\"test\"} loaders\n",
    "    device,\n",
    "    epochs_per_domain=3,\n",
    "    pseudo_thresh=0.8,\n",
    "    lr=1e-4\n",
    "):\n",
    "    # prepare\n",
    "    mt = MeanTeacher(student.to(device), ema_decay=0.995)\n",
    "    optimizer = optim.Adam(mt.student.parameters(), lr=lr)\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    # train ddpm initially on source\n",
    "    ddpm = ddpm.to(device)\n",
    "    optD = optim.Adam(ddpm.parameters(), lr=lr)\n",
    "    for epoch in range(epochs_per_domain):\n",
    "        idx = torch.randperm(len(source_feats))[:512]\n",
    "        h0 = source_feats[idx].to(device)\n",
    "        y0 = source_labels[idx].to(device)\n",
    "        d0 = torch.zeros_like(y0, device=device)  # source domain index=0\n",
    "\n",
    "        h0 = h0.unsqueeze(1)\n",
    "        noise = torch.randn_like(h0)\n",
    "        t = torch.randint(0, scheduler.num_train_timesteps, (h0.size(0),), device=device)\n",
    "\n",
    "        noised = scheduler.add_noise(h0, noise, t)\n",
    "        pred  = ddpm(noised, t, y0, d0)\n",
    "        lossD = mse(pred, noise)\n",
    "        optD.zero_grad(); lossD.backward(); optD.step()\n",
    "\n",
    "    # now continual adaptation\n",
    "    for domain_id, domain in enumerate(domain_order[1:], start=1):\n",
    "        for epoch in range(epochs_per_domain):\n",
    "            mt.student.train()\n",
    "            for imgs, _ in tqdm(data_loaders[domain][\"train\"], desc=f\"[{domain}] Ep{epoch+1}\"):\n",
    "                imgs = imgs.to(device)\n",
    "                B = imgs.size(0)\n",
    "\n",
    "                # -- (1) Teacher pseudo-labels --\n",
    "                with torch.no_grad():\n",
    "                    t_logits = mt.teacher(imgs)\n",
    "                    t_probs  = F.softmax(t_logits, dim=1)\n",
    "                    conf, y_pseudo = t_probs.max(1)\n",
    "                    mask = conf > pseudo_thresh\n",
    "\n",
    "                # -- (2) Student supervised step on pseudo-labels --\n",
    "                if mask.sum() > 0:\n",
    "                    out_s = mt.student(imgs[mask])\n",
    "                    loss_pl = ce(out_s, y_pseudo[mask].to(device))\n",
    "                else:\n",
    "                    loss_pl = torch.tensor(0., device=device)\n",
    "\n",
    "                # -- (3) Diffusion replay --\n",
    "                # sample balanced classes and this domain\n",
    "                cls_ids = torch.randint(0, student.fc.out_features, (B,), device=device)\n",
    "                dom_ids = torch.full((B,), domain_id-1, dtype=torch.long, device=device)\n",
    "                feats_replay = sample_replay_feats(ddpm, scheduler, cls_ids, dom_ids, device)\n",
    "                out_r = mt.student.fc(feats_replay)\n",
    "                loss_re = ce(out_r, cls_ids)\n",
    "\n",
    "                # -- (4) Entropy regularization on all imgs --\n",
    "                out_all = mt.student(imgs)\n",
    "                logp_all = F.log_softmax(out_all, dim=1)\n",
    "                loss_ent = -(F.softmax(out_all, dim=1) * logp_all).sum(1).mean()\n",
    "\n",
    "                # total loss\n",
    "                loss = loss_pl + loss_re + 0.1*loss_ent\n",
    "                optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "\n",
    "                # EMA update\n",
    "                mt.update_teacher()\n",
    "\n",
    "        # end of domain epoch\n",
    "\n",
    "    return mt.student, mt.teacher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptation Model and Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Adaptive ModeL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:30:03.836531Z",
     "iopub.status.busy": "2025-05-06T19:30:03.836211Z",
     "iopub.status.idle": "2025-05-06T19:30:11.520327Z",
     "shell.execute_reply": "2025-05-06T19:30:11.519Z",
     "shell.execute_reply.started": "2025-05-06T19:30:03.836509Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Creating Feature Extractir\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "return_nodes = {\"avgpool\": \"features\"}\n",
    "feature_extractor = create_feature_extractor(base_model, return_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T18:26:29.488296Z",
     "iopub.status.busy": "2025-05-06T18:26:29.488062Z",
     "iopub.status.idle": "2025-05-06T18:26:29.503495Z",
     "shell.execute_reply": "2025-05-06T18:26:29.50288Z",
     "shell.execute_reply.started": "2025-05-06T18:26:29.488273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"FDR_UCDA\",\n",
    "    name=\"mt_diffusion_replay_1d\",\n",
    "    config=dict(\n",
    "        lr=LR, batch=BATCH_SIZE, epochs=6,\n",
    "        diff_steps=DIFFUSION_STEPS, ema=EMA_DECAY,\n",
    "        th_start=TH_START, th_end=TH_END,\n",
    "        ent_weight=ENT_WEIGHT\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-05T05:51:47.96277Z",
     "iopub.status.busy": "2025-05-05T05:51:47.961986Z",
     "iopub.status.idle": "2025-05-05T05:51:47.987754Z",
     "shell.execute_reply": "2025-05-05T05:51:47.986832Z",
     "shell.execute_reply.started": "2025-05-05T05:51:47.962734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### DIFFUSION SETUP\n",
    "scheduler = DPMSolverMultistepScheduler(\n",
    "    num_train_timesteps=DIFF_STEPS, prediction_type=\"epsilon\"\n",
    ")\n",
    "\n",
    "ddpm = UNet1DConditionModel(\n",
    "    sample_size=student.fc.in_features,  # 512 for ResNet‑18\n",
    "    in_channels=1, out_channels=1,\n",
    "    layers_per_block=2,\n",
    "    block_out_channels=(64,64,128,128,256),\n",
    "    down_block_types=(\"DownBlock1D\",\"AttnDownBlock1D\",\"ResnetDownsampleBlock1D\",\"DownBlock1D\",\"DownBlock1D\"),\n",
    "    up_block_types=(\"UpBlock1D\",\"ResnetUpsampleBlock1D\",\"AttnUpBlock1D\",\"UpBlock1D\",\"UpBlock1D\"),\n",
    "    num_class_embeds=len(loaders[\"train\"].dataset.dataset.classes),\n",
    "    class_embeddings_concat=True,\n",
    "    encoder_hid_dim=64\n",
    ").to(device)\n",
    "opt_ddpm = optim.Adam(ddpm.parameters(), lr=LR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom 1d diffusion Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:48.178756Z",
     "iopub.status.busy": "2025-05-06T19:31:48.178199Z",
     "iopub.status.idle": "2025-05-06T19:31:48.1993Z",
     "shell.execute_reply": "2025-05-06T19:31:48.198485Z",
     "shell.execute_reply.started": "2025-05-06T19:31:48.178728Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):  # x: (batch,)\n",
    "        device = x.device\n",
    "        half = self.dim // 2\n",
    "        emb = math.log(10000) / (half - 1)\n",
    "        emb = torch.exp(torch.arange(half, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb  # (batch, dim)\n",
    "\n",
    "class ConditionalUNet1D(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_channels=1,\n",
    "                 base_channels=64,\n",
    "                 channel_mults=(1, 2, 4),\n",
    "                 time_emb_dim=128,\n",
    "                 domain_vocab_size=10,\n",
    "                 class_vocab_size=10,\n",
    "                 cond_emb_dim=32):\n",
    "        super().__init__()\n",
    "        # time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPosEmb(time_emb_dim),\n",
    "            nn.Linear(time_emb_dim, time_emb_dim * 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_emb_dim * 2, time_emb_dim)\n",
    "        )\n",
    "        # domain & class embedding\n",
    "        self.domain_embed = nn.Embedding(domain_vocab_size, cond_emb_dim)\n",
    "        self.class_embed = nn.Embedding(class_vocab_size, cond_emb_dim)\n",
    "        # initial conv\n",
    "        chs = base_channels\n",
    "        self.initial_conv = nn.Conv1d(input_channels, chs, kernel_size=3, padding=1)\n",
    "\n",
    "        # downsample\n",
    "        self.downs = nn.ModuleList()\n",
    "        in_ch = chs\n",
    "        for mult in channel_mults:\n",
    "            out_ch = base_channels * mult\n",
    "            block = nn.Sequential(\n",
    "                nn.SiLU(),\n",
    "                nn.Conv1d(in_ch, out_ch, 3, padding=1),\n",
    "                nn.SiLU(),\n",
    "                nn.Conv1d(out_ch, out_ch, 3, padding=1)\n",
    "            )\n",
    "            down = nn.Module()\n",
    "            down.block = block\n",
    "            down.pool = nn.AvgPool1d(2)\n",
    "            self.downs.append(down)\n",
    "            in_ch = out_ch\n",
    "\n",
    "        # bottleneck\n",
    "        self.mid_block1 = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(in_ch, in_ch, 3, padding=1)\n",
    "        )\n",
    "        self.mid_block2 = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(in_ch, in_ch, 3, padding=1)\n",
    "        )\n",
    "\n",
    "        # upsample\n",
    "        self.ups = nn.ModuleList()\n",
    "        for mult in reversed(channel_mults):\n",
    "            out_ch = base_channels * mult\n",
    "            # block expects concatenated skip(=out_ch) and upsampled h(=out_ch)\n",
    "            block = nn.Sequential(\n",
    "                nn.SiLU(),\n",
    "                nn.Conv1d(out_ch * 2, out_ch, 3, padding=1),\n",
    "                nn.SiLU(),\n",
    "                nn.Conv1d(out_ch, out_ch, 3, padding=1)\n",
    "            )\n",
    "            up = nn.Module()\n",
    "            up.block = block\n",
    "            # transpose conv upsamples h from in_ch to out_ch channels\n",
    "            up.upsample = nn.ConvTranspose1d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "            self.ups.append(up)\n",
    "            in_ch = out_ch\n",
    "\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Conv1d(base_channels, input_channels, 1)\n",
    "        )\n",
    "\n",
    "        # embed to modulate via FiLM\n",
    "        self.time_cond = nn.Linear(time_emb_dim, in_ch)\n",
    "        self.domain_cond = nn.Linear(cond_emb_dim, in_ch)\n",
    "        self.class_cond = nn.Linear(cond_emb_dim, in_ch)\n",
    "\n",
    "    def forward(self, x, t, domain_id, class_id):\n",
    "        # x: (batch, channels, length)\n",
    "        # t: (batch,) timesteps\n",
    "        # domain_id, class_id: (batch,)\n",
    "\n",
    "        t_emb = self.time_mlp(t)\n",
    "        d_emb = self.domain_embed(domain_id)\n",
    "        c_emb = self.class_embed(class_id)\n",
    "\n",
    "        h = self.initial_conv(x)\n",
    "        hs = [h]\n",
    "        for down in self.downs:\n",
    "            h = down.block(h)\n",
    "            hs.append(h)\n",
    "            h = down.pool(h)\n",
    "\n",
    "        h = self.mid_block1(h)\n",
    "        h = self.mid_block2(h)\n",
    "\n",
    "        # Upsample before concatenation to match skip dimensions\n",
    "        for up in self.ups:\n",
    "            skip = hs.pop()\n",
    "            h = up.upsample(h)                        # <-- upsample h\n",
    "            h = torch.cat([h, skip], dim=1)           # <-- then concat skip\n",
    "            h = up.block(h)\n",
    "\n",
    "        cond = self.time_cond(t_emb) + self.domain_cond(d_emb) + self.class_cond(c_emb)\n",
    "        cond = cond.unsqueeze(-1)\n",
    "        h = h * (1 + cond)\n",
    "        return self.final_conv(h)\n",
    "\n",
    "\n",
    "class GaussianDiffusion1D(nn.Module):\n",
    "    def __init__(self, model, seq_length, timesteps=1000, beta_start=1e-4, beta_end=0.02, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.seq_length = seq_length\n",
    "        self.timesteps = timesteps\n",
    "        self.device = device\n",
    "        # linear schedule\n",
    "        self.register_buffer('betas', torch.linspace(beta_start, beta_end, timesteps))\n",
    "        alphas = 1.0 - self.betas\n",
    "        alphas_cum = torch.cumprod(alphas, dim=0)\n",
    "        self.register_buffer('alphas_cum', alphas_cum)\n",
    "        self.register_buffer('sqrt_alphas_cum', torch.sqrt(alphas_cum))\n",
    "        self.register_buffer('sqrt_one_minus_ac', torch.sqrt(1 - alphas_cum))\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "        sqrt_ac = self.sqrt_alphas_cum[t].view(-1, 1, 1)\n",
    "        sqrt_om = self.sqrt_one_minus_ac[t].view(-1, 1, 1)\n",
    "        return sqrt_ac * x_start + sqrt_om * noise\n",
    "\n",
    "    def p_losses(self, x_start, t, domain_id, class_id, noise=None):\n",
    "        noise = noise or torch.randn_like(x_start)\n",
    "        x_noisy = self.q_sample(x_start, t, noise)\n",
    "        predicted = self.model(x_noisy, t, domain_id, class_id)\n",
    "        return F.mse_loss(predicted, noise)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size, domain_id, class_id):\n",
    "        x = torch.randn(batch_size, 1, self.seq_length, device=self.device)\n",
    "        for i in reversed(range(self.timesteps)):\n",
    "            t = torch.full((batch_size,), i, device=self.device, dtype=torch.long)\n",
    "            noise_pred = self.model(x, t, domain_id, class_id)\n",
    "            beta = self.betas[t].view(-1, 1, 1)\n",
    "            alpha = 1 - beta\n",
    "            x = (x - beta.sqrt() * noise_pred) / alpha.sqrt()\n",
    "            if i > 0:\n",
    "                x = x + torch.sqrt(beta) * torch.randn_like(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:30:23.007786Z",
     "iopub.status.busy": "2025-05-06T19:30:23.007057Z",
     "iopub.status.idle": "2025-05-06T19:30:23.020741Z",
     "shell.execute_reply": "2025-05-06T19:30:23.019624Z",
     "shell.execute_reply.started": "2025-05-06T19:30:23.007753Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"1d_conditional_diffusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:54.256242Z",
     "iopub.status.busy": "2025-05-06T19:31:54.255696Z",
     "iopub.status.idle": "2025-05-06T19:31:54.268474Z",
     "shell.execute_reply": "2025-05-06T19:31:54.267509Z",
     "shell.execute_reply.started": "2025-05-06T19:31:54.256221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_diffusion(\n",
    "    diffusion: GaussianDiffusion1D,\n",
    "    model: nn.Module,\n",
    "    extractor: nn.Module,\n",
    "    loaders: dict,\n",
    "    domain_label: int,\n",
    "    epochs: int = 10,\n",
    "    lr: float = 1e-4,\n",
    "    device: str = 'cuda'\n",
    "):\n",
    "    optimizer = torch.optim.Adam(diffusion.model.parameters(), lr=lr)\n",
    "    diffusion.to(device)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # Training phase\n",
    "        diffusion.model.train()\n",
    "        train_loss = 0.0\n",
    "        for imgs, class_ids in loaders['train']:\n",
    "            imgs = imgs.to(device)\n",
    "            class_ids = class_ids.to(device)\n",
    "            with torch.no_grad():\n",
    "                feats = extractor(imgs)[\"features\"]  # (B, 1, L)\n",
    "                feats = feats.squeeze().squeeze().unsqueeze(1)\n",
    "\n",
    "            bsz = feats.size(0)\n",
    "            t = torch.randint(0, diffusion.timesteps, (bsz,), device=device).long()\n",
    "            domain_ids = torch.full((bsz,), domain_label, device=device, dtype=torch.long)\n",
    "            loss = diffusion.p_losses(feats, t, domain_ids, class_ids)\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * bsz\n",
    "\n",
    "        train_loss /= len(loaders['train'].dataset)\n",
    "\n",
    "        # Validation phase\n",
    "        diffusion.model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for imgs, class_ids in loaders['val']:\n",
    "                imgs = imgs.to(device)\n",
    "                class_ids = class_ids.to(device)\n",
    "                feats = extractor(imgs)[\"features\"]\n",
    "                feats = feats.squeeze().squeeze().unsqueeze(1)\n",
    "                bsz = feats.size(0)\n",
    "                t = torch.randint(0, diffusion.timesteps, (bsz,), device=device).long()\n",
    "                domain_ids = torch.full((bsz,), domain_label, device=device, dtype=torch.long)\n",
    "                loss = diffusion.p_losses(feats, t, domain_ids, class_ids)\n",
    "\n",
    "                val_loss += loss.item() * bsz\n",
    "        val_loss /= len(loaders['val'].dataset)\n",
    "                # Log metrics to W&B\n",
    "        wandb.log({\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "        # print(f\"Epoch {epoch}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "    # Testing (optional)\n",
    "    diffusion.model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, class_ids in loaders['test']:\n",
    "            imgs = imgs.to(device)\n",
    "            class_ids = class_ids.to(device)\n",
    "            feats = extractor(imgs)[\"features\"]\n",
    "            feats = feats.squeeze().squeeze().unsqueeze(1)\n",
    "            bsz = feats.size(0)\n",
    "            t = torch.randint(0, diffusion.timesteps, (bsz,), device=device).long()\n",
    "            domain_ids = torch.full((bsz,), domain_label, device=device, dtype=torch.long)\n",
    "            loss = diffusion.p_losses(feats, t, domain_ids, class_ids)\n",
    "            test_loss += loss.item() * bsz\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    wandb.log({\"test_loss\": test_loss})\n",
    "    print(f\"Test Loss = {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:31:57.176821Z",
     "iopub.status.busy": "2025-05-06T19:31:57.176534Z",
     "iopub.status.idle": "2025-05-06T19:31:57.180729Z",
     "shell.execute_reply": "2025-05-06T19:31:57.179935Z",
     "shell.execute_reply.started": "2025-05-06T19:31:57.176802Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "domain_vocab_size = 4\n",
    "class_vocab_size = 65\n",
    "seq_length = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:34:01.51191Z",
     "iopub.status.busy": "2025-05-06T19:34:01.511304Z",
     "iopub.status.idle": "2025-05-06T19:34:01.566268Z",
     "shell.execute_reply": "2025-05-06T19:34:01.565559Z",
     "shell.execute_reply.started": "2025-05-06T19:34:01.511888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = ConditionalUNet1D(\n",
    "    input_channels=1,\n",
    "    base_channels=64,\n",
    "    channel_mults=(1, 2, 4),\n",
    "    time_emb_dim=128,\n",
    "    domain_vocab_size=domain_vocab_size,\n",
    "    class_vocab_size=class_vocab_size,\n",
    "    cond_emb_dim=32\n",
    ").to(device)\n",
    "\n",
    "diffusion = GaussianDiffusion1D(\n",
    "    model,\n",
    "    seq_length=seq_length,\n",
    "    timesteps=1000,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Choose which domain to train on (0 through 3)\n",
    "domain_label = 0  # e.g. first domain\n",
    "\n",
    "# Start training\n",
    "# train_diffusion(\n",
    "#     diffusion=diffusion,\n",
    "#     model=model,\n",
    "#     extractor=feature_extractor,\n",
    "#     loaders=rw_loaders,\n",
    "#     domain_label=domain_label,\n",
    "#     epochs=20,\n",
    "#     lr=2e-4,\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "diffusion.load_state_dict(torch.load(\"diffusion.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T18:40:11.168403Z",
     "iopub.status.busy": "2025-05-06T18:40:11.167911Z",
     "iopub.status.idle": "2025-05-06T18:40:11.189348Z",
     "shell.execute_reply": "2025-05-06T18:40:11.188619Z",
     "shell.execute_reply.started": "2025-05-06T18:40:11.168379Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(diffusion.state_dict(), \"diffusion.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:16:26.895616Z",
     "iopub.status.busy": "2025-05-06T19:16:26.894873Z",
     "iopub.status.idle": "2025-05-06T19:16:26.933672Z",
     "shell.execute_reply": "2025-05-06T19:16:26.932711Z",
     "shell.execute_reply.started": "2025-05-06T19:16:26.895588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "domain_ids = torch.full((64,), 0, device=device, dtype=torch.long)\n",
    "class_ids = torch.full((64,), 1, device=device, dtype=torch.long)\n",
    "print(torch_ids.shape, class_ids.shape)\n",
    "diffusion.sample(64, domain_ids, class_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have base trained model and the diffusion model with us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary results on different domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:32:05.375321Z",
     "iopub.status.busy": "2025-05-06T19:32:05.374538Z",
     "iopub.status.idle": "2025-05-06T19:32:05.379082Z",
     "shell.execute_reply": "2025-05-06T19:32:05.378283Z",
     "shell.execute_reply.started": "2025-05-06T19:32:05.375298Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loader_dict = {\"RealWorld\":rw_loaders, \"Product\": pr_loader, \"Art\": art_loader, \"ClipArt\": cart_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:45:58.222726Z",
     "iopub.status.busy": "2025-05-06T19:45:58.222418Z",
     "iopub.status.idle": "2025-05-06T19:45:58.22844Z",
     "shell.execute_reply": "2025-05-06T19:45:58.227639Z",
     "shell.execute_reply.started": "2025-05-06T19:45:58.222705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_accuracy(model, loader_dict):\n",
    "    for key, loader in loader_dict.items():\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y in loader['test']:\n",
    "                x,y = x.to(device), y.to(device)\n",
    "                pred = model(x).argmax(1)\n",
    "                correct += (pred==y).sum().item(); total += y.size(0)\n",
    "        print(f\"Accuracy on {key}:\", 100*correct/total)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:00:38.512105Z",
     "iopub.status.busy": "2025-05-06T13:00:38.511851Z",
     "iopub.status.idle": "2025-05-06T13:00:57.042463Z",
     "shell.execute_reply": "2025-05-06T13:00:57.041876Z",
     "shell.execute_reply.started": "2025-05-06T13:00:38.512086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_accuracy(base_model, loader_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapting without Diffusion Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:30:27.764246Z",
     "iopub.status.busy": "2025-05-06T13:30:27.763972Z",
     "iopub.status.idle": "2025-05-06T13:30:28.759292Z",
     "shell.execute_reply": "2025-05-06T13:30:28.758743Z",
     "shell.execute_reply.started": "2025-05-06T13:30:27.764225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:30:33.665914Z",
     "iopub.status.busy": "2025-05-06T13:30:33.665562Z",
     "iopub.status.idle": "2025-05-06T13:34:49.443825Z",
     "shell.execute_reply": "2025-05-06T13:34:49.442677Z",
     "shell.execute_reply.started": "2025-05-06T13:30:33.665891Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "noreplay = deepcopy(base_model)\n",
    "\n",
    "# Adapting on Product\n",
    "noreplay = adapt_wo_replay(noreplay, loader_dict[\"Product\"], epochs=20, threshold_start=0.5, threshold_end=0.8,\n",
    "    lr=1e-5, weight_decay=1e-4, alpha=0.7, ema_decay=0.99, device='cuda', patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:36:42.415319Z",
     "iopub.status.busy": "2025-05-06T13:36:42.414798Z",
     "iopub.status.idle": "2025-05-06T13:36:59.145557Z",
     "shell.execute_reply": "2025-05-06T13:36:59.144946Z",
     "shell.execute_reply.started": "2025-05-06T13:36:42.415296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# noreplay.load_state_dict(torch.load(\"best_model_7.pth\", weights_only=True))\n",
    "test_accuracy(noreplay, loader_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:37:50.489242Z",
     "iopub.status.busy": "2025-05-06T13:37:50.48855Z",
     "iopub.status.idle": "2025-05-06T13:43:44.035643Z",
     "shell.execute_reply": "2025-05-06T13:43:44.034684Z",
     "shell.execute_reply.started": "2025-05-06T13:37:50.489216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Adapting on Art\n",
    "noreplay = adapt_wo_replay(noreplay, loader_dict[\"Art\"], epochs=20, threshold_start=0.6, threshold_end=0.8,\n",
    "    lr=1e-5, weight_decay=1e-4, alpha=0.7, ema_decay=0.99, device='cuda', patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:46:21.001324Z",
     "iopub.status.busy": "2025-05-06T13:46:21.000582Z",
     "iopub.status.idle": "2025-05-06T13:46:40.167046Z",
     "shell.execute_reply": "2025-05-06T13:46:40.166252Z",
     "shell.execute_reply.started": "2025-05-06T13:46:21.001298Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "noreplay.load_state_dict(torch.load(\"best_model_6.pth\", weights_only=True))\n",
    "test_accuracy(noreplay, loader_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:47:17.906585Z",
     "iopub.status.busy": "2025-05-06T13:47:17.906026Z",
     "iopub.status.idle": "2025-05-06T13:50:47.154076Z",
     "shell.execute_reply": "2025-05-06T13:50:47.152708Z",
     "shell.execute_reply.started": "2025-05-06T13:47:17.90656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Adapting on Art\n",
    "noreplay = adapt_wo_replay(noreplay, loader_dict[\"ClipArt\"], epochs=20, threshold_start=0.6, threshold_end=0.8,\n",
    "    lr=1e-5, weight_decay=1e-4, alpha=0.7, ema_decay=0.99, device='cuda', patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T13:51:01.227792Z",
     "iopub.status.busy": "2025-05-06T13:51:01.227498Z",
     "iopub.status.idle": "2025-05-06T13:51:18.164229Z",
     "shell.execute_reply": "2025-05-06T13:51:18.163662Z",
     "shell.execute_reply.started": "2025-05-06T13:51:01.227746Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "noreplay.load_state_dict(torch.load(\"best_model_4.pth\", weights_only=True))\n",
    "test_accuracy(noreplay, loader_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:00:39.889259Z",
     "iopub.status.busy": "2025-05-06T14:00:39.888533Z",
     "iopub.status.idle": "2025-05-06T14:08:00.070696Z",
     "shell.execute_reply": "2025-05-06T14:08:00.069657Z",
     "shell.execute_reply.started": "2025-05-06T14:00:39.889233Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "noreplay = deepcopy(base_model)\n",
    "\n",
    "# Adapting on Product\n",
    "noreplay = adapt_wo_replay(noreplay, loader_dict[\"ClipArt\"], epochs=30, threshold_start=0.2, threshold_end=0.9,\n",
    "    lr=1e-5, weight_decay=1e-4, alpha=0.5, ema_decay=0.995, device='cuda', patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T14:08:10.179313Z",
     "iopub.status.busy": "2025-05-06T14:08:10.179047Z",
     "iopub.status.idle": "2025-05-06T14:08:28.702156Z",
     "shell.execute_reply": "2025-05-06T14:08:28.701562Z",
     "shell.execute_reply.started": "2025-05-06T14:08:10.179294Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_accuracy(noreplay, loader_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:57:14.492669Z",
     "iopub.status.busy": "2025-05-06T19:57:14.492371Z",
     "iopub.status.idle": "2025-05-06T19:57:14.512022Z",
     "shell.execute_reply": "2025-05-06T19:57:14.511076Z",
     "shell.execute_reply.started": "2025-05-06T19:57:14.492646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def adapt_with_diffusion_replay(\n",
    "    model,\n",
    "    loaders,\n",
    "    epochs,\n",
    "    threshold_start,\n",
    "    threshold_end,\n",
    "    prev_domains,\n",
    "    diffusion,\n",
    "    diffusion_threshold=0.9,\n",
    "    diffusion_ratio=0.3,\n",
    "    lr=1e-5,\n",
    "    weight_decay=1e-4,\n",
    "    alpha=0.5,\n",
    "    ema_decay=0.999,\n",
    "    device='cuda',\n",
    "    patience=3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Continual adaptation for ResNet with EMA teacher-student and diffusion feature replay.\n",
    "\n",
    "    Assumes `model` is a ResNet (e.g., torchvision.models.resnet) where:\n",
    "      - backbone = all layers except the final `fc`\n",
    "      - classifier = model.fc\n",
    "\n",
    "    Args:\n",
    "        model: ResNet model.\n",
    "        loaders: dict with 'train' and 'val' DataLoaders.\n",
    "        epochs: number of epochs.\n",
    "        threshold_start: initial confidence threshold for real data.\n",
    "        threshold_end: final confidence threshold for real data.\n",
    "        prev_domains: list of domain ids previously seen.\n",
    "        diffusion: diffusion model providing features via `.sample_features(batch_size, domain_ids, class_ids)`.\n",
    "        diffusion_threshold: fixed threshold for pseudo-labeling diffusion samples.\n",
    "        diffusion_ratio: fraction of each batch replaced by diffusion data.\n",
    "        lr, weight_decay, alpha, ema_decay, device, patience: hyperparams.\n",
    "    \"\"\"\n",
    "    # Separate backbone and classifier\n",
    "    # Backbone: all layers except final fc\n",
    "    backbone = nn.Sequential(*list(model.children())[:-1]).to(device)\n",
    "    classifier = model.fc.to(device)\n",
    "    feature_dim = model.fc.in_features\n",
    "\n",
    "    # EMA teacher\n",
    "    teacher_backbone = deepcopy(backbone)\n",
    "    teacher_classifier = deepcopy(classifier)\n",
    "    for p in teacher_backbone.parameters(): p.requires_grad = False\n",
    "    for p in teacher_classifier.parameters(): p.requires_grad = False\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        list(backbone.parameters()) + list(classifier.parameters()),\n",
    "        lr=lr, weight_decay=weight_decay\n",
    "    )\n",
    "    criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "    total_steps = epochs * len(loaders['train'])\n",
    "    step = 0\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_ckpt = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        backbone.train(); classifier.train()\n",
    "        teacher_backbone.train(); teacher_classifier.train()\n",
    "\n",
    "        for imgs, _ in loaders['train']:\n",
    "            imgs = imgs.to(device)\n",
    "            batch_size = imgs.size(0)\n",
    "            step += 1\n",
    "\n",
    "            # split counts\n",
    "            n_diff = int(batch_size * diffusion_ratio)\n",
    "            n_real = batch_size - n_diff\n",
    "            real_imgs = imgs[:n_real]\n",
    "\n",
    "            # diffusion features\n",
    "            if n_diff > 0:\n",
    "                domain_ids = torch.tensor(\n",
    "                    [prev_domains[i % len(prev_domains)] for i in range(n_diff)],\n",
    "                    device=device, dtype=torch.long)\n",
    "                class_ids = torch.randint(\n",
    "                    0, 65, (n_diff,), device=device)\n",
    "                # print(domain_ids, n_diff, class_ids)\n",
    "                # return\n",
    "                diff_feats = diffusion.sample(n_diff, domain_ids, class_ids)\n",
    "            else:\n",
    "                diff_feats = torch.empty((0, feature_dim), device=device)\n",
    "\n",
    "            # Teacher predictions\n",
    "            with torch.no_grad():\n",
    "                t_feats_real = backbone(real_imgs).view(n_real, -1)\n",
    "                t_logits_real = teacher_classifier(t_feats_real)\n",
    "                t_probs_real = F.softmax(t_logits_real, dim=1)\n",
    "\n",
    "                if n_diff > 0:\n",
    "                    t_logits_diff = teacher_classifier(diff_feats)\n",
    "                    t_probs_diff = F.softmax(t_logits_diff, dim=1)\n",
    "                else:\n",
    "                    t_probs_diff = torch.empty((0, t_probs_real.size(1)), device=device)\n",
    "                # print(t_probs_real.size(), t_probs_diff.size())\n",
    "                t_probs = torch.cat([t_probs_real, t_probs_diff.squeeze()], dim=0)\n",
    "\n",
    "            # Student predictions\n",
    "            s_feats_real = backbone(real_imgs).view(n_real, -1)\n",
    "            s_logits_real = classifier(s_feats_real)\n",
    "            s_logprobs_real = F.log_softmax(s_logits_real, dim=1)\n",
    "\n",
    "            if n_diff > 0:\n",
    "                s_logits_diff = classifier(diff_feats)\n",
    "                s_logprobs_diff = F.log_softmax(s_logits_diff, dim=1)\n",
    "            else:\n",
    "                s_logprobs_diff = torch.empty((0, s_logprobs_real.size(1)), device=device)\n",
    "\n",
    "            s_logprobs = torch.cat([s_logprobs_real, s_logprobs_diff.squeeze()], dim=0)\n",
    "\n",
    "            # thresholds\n",
    "            dynamic_thresh = threshold_start + (threshold_end - threshold_start) * (step / total_steps)\n",
    "            conf = t_probs.max(dim=1).values\n",
    "            mask_real = conf[:n_real] > dynamic_thresh\n",
    "            mask_diff = conf[n_real:] > diffusion_threshold\n",
    "\n",
    "            # losses\n",
    "            loss_pseudo = torch.tensor(0.0, device=device)\n",
    "            if mask_real.any():\n",
    "                loss_pseudo += criterion(\n",
    "                    s_logprobs_real[mask_real], t_probs_real[mask_real])\n",
    "            if mask_diff.any():\n",
    "                loss_pseudo += criterion(\n",
    "                    s_logprobs_diff[mask_diff], t_probs_diff[mask_diff])\n",
    "\n",
    "            loss_ent = -(s_logprobs.exp() * s_logprobs).sum(dim=1).mean()\n",
    "            loss = alpha * loss_pseudo + (1 - alpha) * loss_ent\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # EMA update\n",
    "            with torch.no_grad():\n",
    "                for tb, b in zip(teacher_backbone.parameters(), backbone.parameters()):\n",
    "                    tb.data.mul_(ema_decay).add_(b.data, alpha=1-ema_decay)\n",
    "                for tc, c in zip(teacher_classifier.parameters(), classifier.parameters()):\n",
    "                    tc.data.mul_(ema_decay).add_(c.data, alpha=1-ema_decay)\n",
    "\n",
    "        # validate\n",
    "        # rebuild model for validation\n",
    "        model.fc = classifier\n",
    "        # backbone doesn't include fc, so reattach\n",
    "        # assume validate uses model directly\n",
    "        val_acc = validate(model, loaders['val'])\n",
    "        print(f\"Epoch {epoch}: Val Acc={val_acc:.2f}%\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            best_ckpt = {\n",
    "                'backbone': deepcopy(backbone.state_dict()),\n",
    "                'classifier': deepcopy(classifier.state_dict())\n",
    "            }\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter > patience:\n",
    "            print(\"Patience exceeded, loading best weights.\")\n",
    "            backbone.load_state_dict(best_ckpt['backbone'])\n",
    "            classifier.load_state_dict(best_ckpt['classifier'])\n",
    "            break\n",
    "\n",
    "    # attach final weights\n",
    "    model = deepcopy(model)\n",
    "    model.fc.load_state_dict(classifier.state_dict())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:37:04.157136Z",
     "iopub.status.busy": "2025-05-06T19:37:04.156821Z",
     "iopub.status.idle": "2025-05-06T19:37:04.182313Z",
     "shell.execute_reply": "2025-05-06T19:37:04.181171Z",
     "shell.execute_reply.started": "2025-05-06T19:37:04.157113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:35:46.956316Z",
     "iopub.status.busy": "2025-05-06T19:35:46.955767Z",
     "iopub.status.idle": "2025-05-06T19:35:46.962396Z",
     "shell.execute_reply": "2025-05-06T19:35:46.961554Z",
     "shell.execute_reply.started": "2025-05-06T19:35:46.956287Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "diffusion = diffusion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-06T19:57:23.349172Z",
     "iopub.status.busy": "2025-05-06T19:57:23.348533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_model = deepcopy(base_model)\n",
    "new_model = adapt_with_diffusion_replay(\n",
    "    new_model,\n",
    "    loaders[\"Product\"],\n",
    "    epochs=30,\n",
    "    threshold_start=0.5,\n",
    "    threshold_end=0.9,\n",
    "    prev_domains=[0],\n",
    "    diffusion=diffusion,\n",
    "    diffusion_threshold=0.9,\n",
    "    diffusion_ratio=0.3,\n",
    "    lr=1e-5,\n",
    "    weight_decay=1e-4,\n",
    "    alpha=0.5,\n",
    "    ema_decay=0.995,\n",
    "    device='cuda',\n",
    "    patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_accuracy(new_model, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_accuracy(new_model, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2609958,
     "sourceId": 4458388,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6054396,
     "sourceId": 9864085,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
